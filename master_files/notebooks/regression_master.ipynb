{"cells":[{"cell_type":"markdown","source":["#### Load Libraries, Data, and Define Evaluation Functions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d7843585-7f0e-4be9-98dd-32f8cd2a33cc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# SKLearn Metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import median_absolute_error\n\ndef get_scores(y_test, predictions):\n    RMSE = mean_squared_error(y_test, predictions, squared=False)\n    R2 = r2_score(y_test, predictions)\n\n    print('RMSE:    ', int(RMSE))\n    print('R2:      ', R2.round(4))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e153c48f-e70a-43ed-b65e-253e0b2a391e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# MLlib Metrics\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\ndef mllib_metrics(predictions):\n    rmse = RegressionEvaluator(labelCol=\"Scores\", predictionCol=\"prediction\", metricName=\"rmse\")\n    rmse = rmse.evaluate(predictions)\n    print(rmse)\n\n    r2 = RegressionEvaluator(labelCol=\"Scores\", predictionCol=\"prediction\", metricName=\"r2\")\n    r2 = r2.evaluate(predictions)\n    print(r2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"913a079c-3975-485f-9fd3-3e95eb449642","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Again, we wanted to use data that we are familiar with from CSE 450.\ndf = spark.read.options(header='True', inferSchema='True', delimiter=',').csv('dbfs:/FileStore/bitamss_mlib/score.csv')\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"64c1d001-3616-444b-b115-557eb537297b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[2.5,21],[5.1,47],[3.2,27],[8.5,75],[3.5,30],[1.5,20],[9.2,88],[5.5,60],[8.3,81],[2.7,25],[7.7,85],[5.9,62],[4.5,41],[3.3,42],[1.1,17],[8.9,95],[2.5,30],[1.9,24],[6.1,67],[7.4,69],[2.7,30],[4.8,54],[3.8,35],[6.9,76],[7.8,86]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Hours","type":"\"double\"","metadata":"{}"},{"name":"Scores","type":"\"integer\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Hours</th><th>Scores</th></tr></thead><tbody><tr><td>2.5</td><td>21</td></tr><tr><td>5.1</td><td>47</td></tr><tr><td>3.2</td><td>27</td></tr><tr><td>8.5</td><td>75</td></tr><tr><td>3.5</td><td>30</td></tr><tr><td>1.5</td><td>20</td></tr><tr><td>9.2</td><td>88</td></tr><tr><td>5.5</td><td>60</td></tr><tr><td>8.3</td><td>81</td></tr><tr><td>2.7</td><td>25</td></tr><tr><td>7.7</td><td>85</td></tr><tr><td>5.9</td><td>62</td></tr><tr><td>4.5</td><td>41</td></tr><tr><td>3.3</td><td>42</td></tr><tr><td>1.1</td><td>17</td></tr><tr><td>8.9</td><td>95</td></tr><tr><td>2.5</td><td>30</td></tr><tr><td>1.9</td><td>24</td></tr><tr><td>6.1</td><td>67</td></tr><tr><td>7.4</td><td>69</td></tr><tr><td>2.7</td><td>30</td></tr><tr><td>4.8</td><td>54</td></tr><tr><td>3.8</td><td>35</td></tr><tr><td>6.9</td><td>76</td></tr><tr><td>7.8</td><td>86</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Data Preprocessing\n----\n\nFeatures: Hours (Spent studying in hours)\n\nTarget: Scores (Grade received)\n\n#### Splitting Datasets\n\n[Documentation for Splitting Datasets using MLlib](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.randomSplit.html)\n\n##### Scaling, Normalizing, Bucketizing, etc.\n\n[Documentation for Feature Extraction using MLlib](https://spark.apache.org/docs/1.4.1/ml-features.html)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"60f4ee16-7fc9-480f-b682-1ca8775cba47","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["###### MLlib"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e44f6762-f51c-40df-bbfe-cd2e64a7f990","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import MinMaxScaler\n\n# 80% for training. 20% for testing.\ntrain_data, test_data = df.randomSplit([0.8, 0.2])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f9bb80f6-4472-4ef5-b18b-33c1b1d671e3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###### SKlearn"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"290d0d1e-5c1d-467b-a36b-f5d330912c32","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler as MinMaxScalerSK\nimport pandas as pd\n\ntrain_sk = train_data.toPandas()\ntest_sk = test_data.toPandas()\n\nsc = MinMaxScalerSK()\ntrain_sk[['Scaled_Hours']] = sc.fit_transform(train_sk[['Hours']])\ntest_sk[['Scaled_Hours']] = sc.transform(test_sk[['Hours']])\n\ntrain_sk = pd.DataFrame(train_sk, columns = train_sk.columns)\ntest_sk = pd.DataFrame(test_sk, columns = test_sk.columns)\n\nx_train_sk = train_sk[['Scaled_Hours']]\ny_train_sk = train_sk[['Scores']]\n\nx_test_sk = test_sk[['Scaled_Hours']]\ny_test_sk = test_sk[['Scores']]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"19ea2c2e-3c6c-44b6-a0a4-a08d961d4f15","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Gradient Boosted Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2f41d4e0-789e-4118-8b90-e2b7dff30d35","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["###### SKlearn"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7f4439e9-8f36-4663-9494-9a8ec3da1637","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingRegressor\nmodel_gb = GradientBoostingRegressor()\nmodel_gb.fit(x_train_sk, y_train_sk)\npredictions = model_gb.predict(x_test_sk)\nget_scores(y_test_sk, predictions)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"87ea9b4e-1ce8-43cb-b1e5-49679ea22657","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"RMSE:     7\nR2:       0.9204\n/databricks/python/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["RMSE:     7\nR2:       0.9204\n/databricks/python/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###### MLlib\n\n[Documentation on Gradient Boosted Regression Models using MLlib](https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-regression)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dbc0bef3-c6cd-442c-bc7e-d4c64177dae1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.regression import GBTRegressor\n\n# Feature Extractions: https://spark.apache.org/docs/1.4.1/ml-features.html\n\n# VectorAssembler Transformation - Converting column to vector type\nvec_assembler = VectorAssembler(inputCols=['Hours'], outputCol=\"Hours_Vect\")\n\n# MinMaxScaler Transformation\nscaler = MinMaxScaler(inputCol=\"Hours_Vect\", outputCol=\"features\")\n\n# Model & Parameters\ngbt = GBTRegressor(maxDepth=2, labelCol = 'Scores', featuresCol='features')\n\npipeline = Pipeline(stages=[vec_assembler, scaler, gbt])\nmodel = pipeline.fit(train_data)\npred = model.transform(test_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"07bbb6fa-232d-4c14-8aae-8a79a2dc5541","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["mllib_metrics(pred)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c1da6c8b-00fc-4d52-943d-d2a5f5144faa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"8.713959962618295\n0.8995925973816665\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["8.713959962618295\n0.8995925973816665\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Random Forest Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8865c8e1-a719-4e61-bb64-e47ad4ba53d2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["###### SKlearn"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e67d5b70-2627-44f1-9c34-bbf82e417148","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor as RandomForestRegressorSK\nmodel_rf = RandomForestRegressorSK()\nmodel_rf.fit(x_train_sk, y_train_sk)\npredictions = model_rf.predict(x_test_sk)\nget_scores(y_test_sk, predictions)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c462a695-0019-4d54-a95a-36c1e896a4f0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"RMSE:     6\nR2:       0.9489\n/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  original_result = original(self, *args, **kwargs)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["RMSE:     6\nR2:       0.9489\n/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  original_result = original(self, *args, **kwargs)\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###### MLlib\n\n[Documentation on Random Forest Regression using MLlib](https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"166f7a34-e775-41b6-bdd5-407c0ab198a3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml.regression import RandomForestRegressor\n\n# Feature Extractions: https://spark.apache.org/docs/1.4.1/ml-features.html\n\n# VectorAssembler Transformation - Converting column to vector type\nvec_assembler = VectorAssembler(inputCols=['Hours'], outputCol=\"Hours_Vect\")\n\n# MinMaxScaler Transformation\nscaler = MinMaxScaler(inputCol=\"Hours_Vect\", outputCol=\"features\")\n\n# Model & Parameters\nrf = RandomForestRegressor(numTrees=5, maxDepth=2, labelCol = 'Scores', featuresCol='features')\n\npipeline_rf = Pipeline(stages=[vec_assembler, scaler, rf])\nmodel_rf = pipeline_rf.fit(train_data)\npred_rf = model_rf.transform(test_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"94c8ea0a-9b1e-45be-b8c5-9754514fc2d1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["mllib_metrics(pred_rf)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6cbf1b59-4cd3-43ec-971d-48d7782a4038","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+------+\n|            features|Scores|\n+--------------------+------+\n|[0.04938271604938...|    20|\n|[0.1728395061728395]|    30|\n|[0.2962962962962963]|    30|\n|[0.3333333333333333]|    35|\n|[0.9135802469135803]|    75|\n|[0.9629629629629631]|    95|\n+--------------------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+------+\n|            features|Scores|\n+--------------------+------+\n|[0.04938271604938...|    20|\n|[0.1728395061728395]|    30|\n|[0.2962962962962963]|    30|\n|[0.3333333333333333]|    35|\n|[0.9135802469135803]|    75|\n|[0.9629629629629631]|    95|\n+--------------------+------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"regression_master","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":705624586461062}},"nbformat":4,"nbformat_minor":0}
